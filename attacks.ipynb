{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Imports**"
      ],
      "metadata": {
        "id": "KgKr2_WyzbKu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "vjyQJV3gtOi2"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "import math\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as trans\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adam, SGD\n",
        "from tqdm import tqdm\n",
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Set Device**"
      ],
      "metadata": {
        "id": "tVgr3163ziSq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = (\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "QscNpelSzXvj"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model Architecture**"
      ],
      "metadata": {
        "id": "OgB00UP-zuEZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MainConv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, stride, padding):\n",
        "        super(MainConv, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride = stride, padding = padding)\n",
        "        self.out = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv(x)\n",
        "        self.out = out      # to store hidden layer ouput\n",
        "        return out\n",
        "\n",
        "class ResNetBlock(nn.Module):\n",
        "    # ResNet basic block\n",
        "    def __init__(self, in_channels, downsample):\n",
        "        super(ResNetBlock, self).__init__()\n",
        "        if downsample:\n",
        "            stride = 2\n",
        "            out_channels = 2 * in_channels\n",
        "        else:\n",
        "            stride = 1\n",
        "            out_channels = in_channels\n",
        "        self.conv1 = MainConv(in_channels, out_channels, 3, stride = stride, padding = 1)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.conv2 = MainConv(out_channels, out_channels, 3, stride = 1, padding = 1)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        self.convr = nn.Conv2d(in_channels, out_channels, 1, stride = stride, padding = 0) if downsample else None\n",
        "        self.relu = nn.ReLU(inplace = True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        y = self.conv1(x)\n",
        "        y = self.bn1(y)\n",
        "        y = self.relu(y)\n",
        "        y = self.conv2(y)\n",
        "        y = self.bn2(y)\n",
        "        if self.convr is not None:\n",
        "            x = self.convr(x)\n",
        "        return self.relu(x + y)\n",
        "\n",
        "class ResNet20(nn.Module):\n",
        "    def __init__(self, n_classes):\n",
        "        super(ResNet20, self).__init__()\n",
        "        blocks = [MainConv(3, 16, 3, stride = 1, padding = 1), nn.ReLU(inplace = True)]\n",
        "        in_channels = 16\n",
        "        for i in range(9):\n",
        "            if i > 0 and i % 3 == 0:\n",
        "                blocks.append(ResNetBlock(in_channels, True))\n",
        "                in_channels *= 2\n",
        "            else:\n",
        "                blocks.append(ResNetBlock(in_channels, False))\n",
        "        blocks += [nn.AvgPool2d(8), nn.Flatten(), nn.Linear(in_channels, n_classes)]\n",
        "        self.blocks = nn.Sequential(*blocks)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.blocks(x)\n",
        "\n",
        "class PARLModel(nn.Module):\n",
        "    def __init__(self, n_classes = 10, n_ensemble = 3):\n",
        "        # n_ensemble: Number of classifiers in the ensemble\n",
        "        super(PARLModel, self).__init__()\n",
        "        self.nets = nn.ModuleList([ResNet20(n_classes) for _ in range(n_ensemble)])\n",
        "        self.n_ensemble = n_ensemble\n",
        "\n",
        "    def forward(self, x):\n",
        "        return [net(x) for net in self.nets]\n",
        "\n",
        "    def init_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
        "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                stdv = 1. / math.sqrt(m.weight.size(1))\n",
        "                m.weight.data.uniform_(-stdv, stdv)\n",
        "                if m.bias is not None:\n",
        "                    m.bias.data.zero_()\n",
        "            elif isinstance(m, nn.BatchNorm1d):\n",
        "                m.weight.data.fill_(1)\n",
        "                m.bias.data.zero_()"
      ],
      "metadata": {
        "id": "PYEMPb-EzolX"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Attack Codes and Utils**"
      ],
      "metadata": {
        "id": "k4-kGVGh23G_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def FGM(model, X, y = None, eps = 0.03, loss_fn = nn.CrossEntropyLoss(), clip = [0.0, 1.0]):\n",
        "    model.eval()\n",
        "    X = X.to(device)\n",
        "    if y is None:\n",
        "        y_pred_ens = model(X)\n",
        "        y_pred_ens = [torch.argmax(y_pred, -1) for y_pred in y_pred_ens]\n",
        "        y = torch.mode(torch.stack(y_pred_ens, 1)).values\n",
        "    else:\n",
        "        y = y.to(device)\n",
        "    clip = [clip[0].to(device), clip[1].to(device)]\n",
        "\n",
        "    X.requires_grad_(True)\n",
        "    y_pred_ens = model(X)\n",
        "    # loss = sum([loss_fn(nn.functional.softmax(y_pred, dim = -1), y) for y_pred in y_pred_ens]) / len(y_pred_ens)\n",
        "    loss = sum([loss_fn(y_pred, y) for y_pred in y_pred_ens]) / len(y_pred_ens)\n",
        "    loss.backward()\n",
        "    grad_sign = torch.sign(X.grad)\n",
        "    X.grad.zero_()\n",
        "    with torch.no_grad():\n",
        "        X_adv = X + eps * grad_sign\n",
        "        X_adv = torch.maximum(torch.minimum(X_adv, X + eps), X - eps)\n",
        "        X_adv.clamp_(clip[0], clip[1])\n",
        "\n",
        "    return X_adv\n",
        "\n",
        "def PGD(model, X, y = None, eps = 0.03, n_iter = 50, eps_iter = None, loss_fn = nn.CrossEntropyLoss(), clip = [0.0, 1.0]):\n",
        "    model.eval()\n",
        "    X = X.to(device)\n",
        "    if y is None:\n",
        "        y_pred_ens = model(X)\n",
        "        y_pred_ens = [torch.argmax(y_pred, -1) for y_pred in y_pred_ens]\n",
        "        y = torch.mode(torch.stack(y_pred_ens, 1)).values\n",
        "    else:\n",
        "        y = y.to(device)\n",
        "    if eps_iter is None:\n",
        "        eps_iter = eps / n_iter\n",
        "    clip = [clip[0].to(device), clip[1].to(device)]\n",
        "\n",
        "    pertb = torch.rand_like(X) * 2 * eps - eps\n",
        "    X_adv = X.clone().detach() + pertb\n",
        "    X_adv.clamp_(clip[0], clip[1])\n",
        "\n",
        "    for _ in tqdm(range(n_iter), desc = 'Iteration'):\n",
        "        X_adv = FGM(model, X_adv, y = y, eps = eps_iter, loss_fn = loss_fn, clip = clip)\n",
        "        with torch.no_grad():\n",
        "            X_adv = torch.maximum(torch.minimum(X_adv, X + eps), X - eps)\n",
        "\n",
        "    return X_adv\n",
        "\n",
        "def MDI2_FGSM(model, X, y = None, eps = 0.03, n_iter = 50, eps_iter = None, decay = 0.1, prob = 0.1, resize_frac = 0.9, loss_fn = nn.CrossEntropyLoss(), clip = [0.0, 1.0]):\n",
        "    model.eval()\n",
        "    X = X.to(device)\n",
        "    if y is None:\n",
        "        y_pred_ens = model(X)\n",
        "        y_pred_ens = [torch.argmax(y_pred, -1) for y_pred in y_pred_ens]\n",
        "        y = torch.mode(torch.stack(y_pred_ens, 1)).values\n",
        "    else:\n",
        "        y = y.to(device)\n",
        "    if eps_iter is None:\n",
        "        eps_iter = eps / n_iter\n",
        "    clip = [clip[0].to(device), clip[1].to(device)]\n",
        "\n",
        "    X_adv = X.clone().detach()\n",
        "    gn = 0\n",
        "    img_dims = X.shape[-1]\n",
        "    max_pad = max(int(math.floor((1 - resize_frac) * img_dims)), 1)\n",
        "    possible_pad = list(range(1, max_pad + 1))\n",
        "\n",
        "\n",
        "    for _ in tqdm(range(n_iter), desc = 'Iteration'):\n",
        "        X_adv.requires_grad_(True)\n",
        "        pad_i = random.choice(possible_pad)\n",
        "        left_pad = random.choice(range(pad_i + 1))\n",
        "        top_pad = random.choice(range(pad_i + 1))\n",
        "        right_pad = pad_i - left_pad\n",
        "        bottom_pad = pad_i - top_pad\n",
        "        mask = torch.where(torch.rand((len(X), 1, 1, 1)) < prob, 1.0, 0.0).to(device)\n",
        "        X_r = trans.Resize((img_dims - pad_i, img_dims - pad_i), antialias = True)(X_adv)\n",
        "        X_T = torch.nn.functional.pad(X_r, (left_pad, right_pad, top_pad, bottom_pad))\n",
        "        X_T = mask * X_T + (1 - mask) * X_adv\n",
        "        y_pred_ens = model(X_T)\n",
        "        loss = sum([loss_fn(y_pred, y) for y_pred in y_pred_ens]) / len(y_pred_ens)\n",
        "        loss.backward()\n",
        "        grad = X_adv.grad.clone()\n",
        "        X_adv.grad.zero_()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            gn = decay * gn + grad / (torch.norm(grad, p = 1, dim = (1, 2, 3), keepdim = True) + 1e-12)\n",
        "            X_adv = X_adv + eps_iter * torch.sign(gn)\n",
        "            X_adv = torch.maximum(torch.minimum(X_adv, X + eps), X - eps)\n",
        "            X_adv.clamp_(clip[0], clip[1])\n",
        "\n",
        "    return X_adv\n",
        "\n",
        "def SGM(model, X, y = None, eps = 0.03, gamma = 0.5, loss_fn = nn.CrossEntropyLoss(), clip = [0.0, 1.0]):\n",
        "    # This code is specific to our ResNet20 implementation\n",
        "    model.eval()\n",
        "    X = X.to(device)\n",
        "    if y is None:\n",
        "        y_pred_ens = model(X)\n",
        "        y_pred_ens = [torch.argmax(y_pred, -1) for y_pred in y_pred_ens]\n",
        "        y = torch.mode(torch.stack(y_pred_ens, 1)).values\n",
        "    else:\n",
        "        y = y.to(device)\n",
        "    clip = [clip[0].to(device), clip[1].to(device)]\n",
        "    X.requires_grad_(True)\n",
        "    cargo = [model.nets[i].blocks[1](model.nets[i].blocks[0](X)) for i in range(model.n_ensemble)]\n",
        "    ensemble = [model.nets[i].modules() for i in range(model.n_ensemble)]\n",
        "\n",
        "    k = 0\n",
        "    z, skip_out, conv_out = [None for _ in range(4)], [None for _ in range(3)], [None for _ in range(3)]\n",
        "    for M in zip(*ensemble):\n",
        "        if isinstance(M[0], ResNetBlock):\n",
        "            k += 1\n",
        "            if k < 7:\n",
        "                cargo = [M[i](cargo[i]) for i in range(model.n_ensemble)]\n",
        "            else:\n",
        "                z[k - 7] = cargo\n",
        "                if k > 7:\n",
        "                    cargo = [nn.functional.relu(c) for c in cargo]\n",
        "                skip_out[k - 7] = [M[i].convr(cargo[i]) if M[i].convr is not None else cargo[i] for i in range(model.n_ensemble)]\n",
        "                conv_out[k - 7] = [M[i].bn2(M[i].conv2(M[i].relu(M[i].bn1(M[i].conv1(cargo[i]))))) for i in range(model.n_ensemble)]\n",
        "                cargo = [torch.add(skip_out[k - 7][i], conv_out[k - 7][i]) for i in range(model.n_ensemble)]\n",
        "\n",
        "    z[3] = cargo\n",
        "    cargo = [nn.functional.relu(c) for c in cargo]\n",
        "    y_pred_ens = [model.nets[i].blocks[-1](model.nets[i].blocks[-2](model.nets[i].blocks[-3](cargo[i]))) for i in range(model.n_ensemble)]\n",
        "    loss = [loss_fn(y_pred, y) for y_pred in y_pred_ens]\n",
        "\n",
        "    dz_dx, d_skip_out_dx, d_conv_out_dx, d_loss_dx = [[None for __ in range(model.n_ensemble)] for _ in range(4)], [[None for __ in range(model.n_ensemble)] for _ in range(3)], [[None for __ in range(model.n_ensemble)] for _ in range(3)], [[None for __ in range(model.n_ensemble)] for _ in range(3)]\n",
        "    grad1, grad2, grad3, grad4 = [None for _ in range(3)], [None for _ in range(3)], [None for _ in range(3)], [None for _ in range(3)]\n",
        "    for i in range(model.n_ensemble):\n",
        "        for j in range(4):\n",
        "            z[j][i].backward(torch.ones_like(z[j][i]), retain_graph = True)\n",
        "            dz_dx[j][i] = X.grad.clone()\n",
        "            X.grad.zero_()\n",
        "\n",
        "        for j in range(3):\n",
        "            skip_out[j][i].backward(torch.ones_like(skip_out[j][i]), retain_graph = True)\n",
        "            d_skip_out_dx[j][i] = X.grad.clone()\n",
        "            X.grad.zero_()\n",
        "\n",
        "        for j in range(3):\n",
        "            conv_out[j][i].backward(torch.ones_like(conv_out[j][i]), retain_graph = True)\n",
        "            d_conv_out_dx[j][i] = X.grad.clone()\n",
        "            X.grad.zero_()\n",
        "\n",
        "        loss[i].backward(retain_graph = True)\n",
        "        d_loss_dx[i] = X.grad.clone()\n",
        "        X.grad.zero_()\n",
        "\n",
        "        grad1[i] = (d_skip_out_dx[0][i] + gamma * d_conv_out_dx[0][i]) / dz_dx[0][i]\n",
        "        grad2[i] = (d_skip_out_dx[1][i] + gamma * d_conv_out_dx[1][i]) / dz_dx[1][i]\n",
        "        grad3[i] = (d_skip_out_dx[2][i] + gamma * d_conv_out_dx[2][i]) / dz_dx[2][i]\n",
        "        grad4[i] = d_loss_dx[i] / dz_dx[3][i]\n",
        "\n",
        "    overall_grad = sum([dz_dx[0][i] * grad1[i] * grad2[i] * grad3[i] * grad4[i] for i in range(model.n_ensemble)]) / model.n_ensemble\n",
        "    grad_sign = torch.sign(overall_grad)\n",
        "    with torch.no_grad():\n",
        "        X_adv = X + eps * grad_sign\n",
        "        X_adv = torch.maximum(torch.minimum(X_adv, X + eps), X - eps)\n",
        "        X_adv.clamp_(clip[0], clip[1])\n",
        "\n",
        "    return X_adv\n",
        "\n",
        "def multi_attack_eval(model, x, y, show_indiv = False):\n",
        "    y_true = y.to(device)\n",
        "    X = [xi.to(device) for xi in x]\n",
        "    success = [torch.ones_like(y_true) for _ in range(model.n_ensemble + 1)]\n",
        "    for Xi in X:\n",
        "        y_pred_ens = model(Xi)\n",
        "        y_pred_ens = [torch.argmax(y_pred, -1) for y_pred in y_pred_ens]\n",
        "        y_pred = torch.mode(torch.stack(y_pred_ens, 1)).values\n",
        "        success[0] = success[0] * torch.where(y_pred - y_true == 0, 1, 0)\n",
        "        for k, y_pred in enumerate(y_pred_ens):\n",
        "            success[k + 1] = success[k + 1] * torch.where(y_pred - y_true == 0, 1, 0)\n",
        "    acc = [torch.sum(s).item() for s in success]\n",
        "    print(f'Combined Ensemble Accuracy: \\033[92m{np.around(100 * acc[0] / len(y_true), 2)}%\\033[0m')\n",
        "    if show_indiv:\n",
        "        for i in range(1, model.n_ensemble + 1):\n",
        "            print(f'Model-{i} Accuracy: {np.around(100 * acc[i] / len(y_true), 2)}%')"
      ],
      "metadata": {
        "id": "hVJg-1BE22mL"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load Clean Data**"
      ],
      "metadata": {
        "id": "XWI3VuvL0w4W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = 'CIFAR-10' # CIFAR-10, CIFAR-100\n",
        "\n",
        "if dataset == 'CIFAR-10':\n",
        "    mean = torch.tensor([0.4942, 0.4851, 0.4504]).unsqueeze_(0).unsqueeze(-1).unsqueeze_(-1).to(device)\n",
        "    std = torch.tensor([0.2467, 0.2429, 0.2616]).unsqueeze_(0).unsqueeze(-1).unsqueeze_(-1).to(device)\n",
        "    n_classes = 10\n",
        "    avg_std = 0.2504\n",
        "elif dataset == 'CIFAR-100':\n",
        "    mean = torch.tensor([0.5088, 0.4874, 0.4419]).unsqueeze_(0).unsqueeze(-1).unsqueeze_(-1).to(device)\n",
        "    std = torch.tensor([0.2683, 0.2574, 0.2771]).unsqueeze_(0).unsqueeze(-1).unsqueeze_(-1).to(device)\n",
        "    n_classes = 100\n",
        "    avg_std = 0.2676\n",
        "\n",
        "clip_max = (1.0 - mean) / std\n",
        "clip_min = (0.0 - mean) / std\n",
        "\n",
        "x_clean = torch.from_numpy(np.load(f'{dataset}_x_clean_1000.npy'))\n",
        "y_clean = torch.from_numpy(np.load(f'{dataset}_y_clean_1000.npy'))"
      ],
      "metadata": {
        "id": "Fbxq6IUCztAY"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load Pre-trained Models**"
      ],
      "metadata": {
        "id": "2hPPVRtq1Jgg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_ensemble = 3 # Number of classifiers in the enemsemble\n",
        "\n",
        "# Ensemble trained with PARL\n",
        "target_model = PARLModel(n_classes = n_classes, n_ensemble = n_ensemble).to(device)\n",
        "target_model.load_state_dict(torch.load(f'PARL5_{dataset}_ResNet20_3_50epochs_gamma_0.25.pth', map_location = torch.device(device)))\n",
        "\n",
        "# Surrogate ensemble trained with cross entropy loss only, on which the adversarial examples are crafted\n",
        "surrogate_model_1 = PARLModel(n_classes = n_classes, n_ensemble = n_ensemble).to(device)\n",
        "surrogate_model_1.load_state_dict(torch.load(f'Surrogate1_{dataset}_ResNet20.pth', map_location = torch.device(device)))\n",
        "\n",
        "# Surrogate ensemble trained with cross entropy loss only, which gives the black box robust accuracy of surrogate model\n",
        "surrogate_model_2 = PARLModel(n_classes = n_classes, n_ensemble = n_ensemble).to(device)\n",
        "surrogate_model_2.load_state_dict(torch.load(f'Surrogate2_{dataset}_ResNet20.pth', map_location = torch.device(device)))"
      ],
      "metadata": {
        "id": "xApPIpSX0sfg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52685727-02cb-4d38-f59f-bda09eeb0ffa"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Perform PGD Attack**"
      ],
      "metadata": {
        "id": "w9P8Ivrg8KAx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for eps in [0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07]:\n",
        "    print(f'Epsilon {eps}')\n",
        "    for r in range(1, 4):\n",
        "        print(f'Restart-{r}: ', end = '', flush = True)\n",
        "        # since the input is in normalized form, we should adjust eps and eps_iter accordingly\n",
        "        x_adv = PGD(surrogate_model_1, x_clean, eps = eps / avg_std, n_iter = 100, eps_iter = eps / (5 * avg_std), clip = [clip_min, clip_max])\n",
        "        np.save(f'{dataset}_ResNet20_X_PGD_R{r}_00{int(100 * eps)}.npy', x_adv.cpu().numpy())\n",
        "        x_adv = None\n",
        "        torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "C2p9R9II8F-m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Perform MDI2-FGSM Attack**"
      ],
      "metadata": {
        "id": "vLJg8P3v9D6I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for eps in [0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07]:\n",
        "    print(f'Epsilon {eps}')\n",
        "    # since the input is in normalized form, we should adjust eps and eps_iter accordingly\n",
        "    x_adv = MDI2_FGSM(surrogate_model_1, x_clean, eps = eps / avg_std, n_iter = 100, eps_iter = eps / (5 * avg_std), clip = [clip_min, clip_max])\n",
        "    np.save(f'{dataset}_ResNet20_X_MDI2-FGSM_00{int(100 * eps)}.npy', x_adv.cpu().numpy())\n",
        "    x_adv = None\n",
        "    torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "h_4L7TM99DMN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Perform SGM Attack**"
      ],
      "metadata": {
        "id": "QNMXSZAl90_S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for eps in [0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07]:\n",
        "    print(f'Epsilon {eps}\\n')\n",
        "    # since the input is in normalized form, we should adjust eps and eps_iter accordingly\n",
        "    x_adv = SGM(surrogate_model_1, x_clean, eps = eps / avg_std, clip = [clip_min, clip_max])\n",
        "    np.save(f'{dataset}_ResNet20_X_SGM_00{int(100 * eps)}.npy', x_adv.cpu().numpy())\n",
        "    x_adv = None\n",
        "    torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "NBFLuYQj9gw9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Perform All Attacks**"
      ],
      "metadata": {
        "id": "7NDUsyAc-TuS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "show_indiv = True\n",
        "\n",
        "for eps in [0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07]:\n",
        "    print(f'\\nEpsilon {eps}\\n')\n",
        "    sample_list = [\n",
        "        f'{dataset}_ResNet20_X_PGD_R1_00{int(100 * eps)}.npy',\n",
        "        f'{dataset}_ResNet20_X_PGD_R2_00{int(100 * eps)}.npy',\n",
        "        f'{dataset}_ResNet20_X_PGD_R3_00{int(100 * eps)}.npy',\n",
        "        f'{dataset}_ResNet20_X_MDI2-FGSM_00{int(100 * eps)}.npy',\n",
        "        f'{dataset}_ResNet20_X_SGM_00{int(100 * eps)}.npy',\n",
        "    ]\n",
        "    x_adv = [torch.from_numpy(np.load(sample)) for sample in sample_list]\n",
        "    print()\n",
        "    print('SURROGATE-1: ', end = '')\n",
        "    multi_attack_eval(surrogate_model_1, x_adv, y_clean, show_indiv = show_indiv)\n",
        "    print()\n",
        "    print('SURROGATE-2: ', end = '')\n",
        "    multi_attack_eval(surrogate_model_2, x_adv, y_clean, show_indiv = show_indiv)\n",
        "    print()\n",
        "    print('TARGET     : ', end = '')\n",
        "    multi_attack_eval(target_model, x_adv, y_clean, show_indiv = show_indiv)\n",
        "    print()\n",
        "    x_adv = None\n",
        "    torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "KICizQLD-RRn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}